# ðŸ¤– Machine Learning with Python â€“ Course 1 (IBM ML Certificate)

This repo contains all the work I did for **Course 1 â€“ Machine Learning with Python**, part of the [IBM Machine Learning Professional Certificate](https://www.coursera.org/professional-certificates/ibm-machine-learning). It goes from foundational supervised models like linear regression to unsupervised learning, evaluation, and best practices.

---

## ðŸ“š Course Content Overview

The course is organized into 5 modules + 1 final project. Each module has its own folder with labs, transcripts, and a full summary (`README.md`) with detailed insights and notes. Here's what was covered:

---

## ðŸ“¦ Module 1 â€“ Introduction to Machine Learning

- What is Machine Learning? (Supervised, Unsupervised, Reinforcement)
- Common use cases across industries.
- Overview of ML pipelines and where ML fits in the data science process.
- No coding yetâ€”just core ML understanding and terminology.

---

## ðŸ“ˆ Module 2 â€“ Linear & Logistic Regression

**Topics:**

- Simple Linear Regression (SLR)
- Multiple Linear Regression (MLR)
- Logistic Regression (binary classification)

**Key Concepts:**

- OLS (Ordinary Least Squares) to fit regression models.
- MSE as a loss function.
- The sigmoid function for logistic regression.
- Learned to model relationships between features and targets (numeric or binary).
- Evaluated regression fits and prediction accuracy.

---

## ðŸŒ² Module 3 â€“ Classification & Regression Models

Split into two parts:

### ðŸ”¹ Part 1: Decision & Regression Trees

- Decision Trees for classification using entropy, information gain, and Gini impurity.
- Regression Trees for predicting continuous values using MSE-based split criteria.
- Tree pruning to avoid overfitting.

### ðŸ”¹ Part 2: KNN, SVM & Ensemble Methods

- **K-Nearest Neighbors (KNN)**: instance-based learner, works on proximity.
- **Support Vector Machines (SVM)**: uses optimal separating hyperplanes.
- **Ensemble Learning**:
  - Bagging (Random Forests) â†’ reduces variance.
  - Boosting (XGBoost, AdaBoost) â†’ reduces bias.
- **Bias-Variance Tradeoff** and how ensemble models help with generalization.

---

## ðŸ§ª Module 4 â€“ Unsupervised Learning

### ðŸ”¸ Clustering

- K-Means clustering (centroid-based)
- DBSCAN & HDBSCAN (density-based)
- Hierarchical clustering (agglomerative/divisive)
- Use cases: customer segmentation, anomaly detection, image segmentation.

### ðŸ”¸ Dimensionality Reduction & Feature Engineering

- PCA (linear reduction)
- t-SNE and UMAP (nonlinear, good for visualization)
- Explained how these techniques reduce dimensions while keeping relevant structure.
- Connected clustering + dimensionality reduction + feature selection.

---

## âœ… Module 5 â€“ Evaluating and Validating ML Models

### ðŸ”¹ Part 1: Evaluation Techniques

- **Classification Metrics**: Accuracy, Precision, Recall, F1 Score, Confusion Matrix
- **Regression Metrics**: MAE, MSE, RMSE, RÂ², Residual plots
- **Unsupervised Evaluation**:
  - Internal: Silhouette score, Davies-Bouldin, Calinski-Harabasz
  - External: Adjusted Rand Index, Normalized Mutual Info
  - Dimensionality evaluation: Explained variance, reconstruction error

### ðŸ”¹ Part 2: Best Practices for Generalization

- Train/Validation/Test splits
- K-Fold and Stratified Cross-Validation
- TimeSeriesSplit for temporal datasets
- **Regularization**:
  - Ridge (L2): shrinks all coefficients
  - Lasso (L1): shrinks some to zero (feature selection)
- **Avoiding Pitfalls**:
  - Data leakage & data snooping
  - Misinterpreting feature importance
  - Causal inference mistakes

---

## ðŸŽ¯ Final Project â€“ Rain Prediction in Australia

- **Goal**: Predict `RainTomorrow` using weather data.
- Applied preprocessing, visualization, multiple models (Logistic Regression, Random Forest).
- Used proper train/test split, cross-validation, hyperparameter tuning, evaluation.
- Avoided data leakage and addressed class imbalance.

---

## ðŸ›  Tools & Libraries

- Python 3.x
- Pandas, NumPy
- Scikit-learn
- Seaborn, Matplotlib
- XGBoost, HDBSCAN
- PCA, t-SNE, UMAP

---
