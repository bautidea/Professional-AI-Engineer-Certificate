{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.1\n",
      "  Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.17.1)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.17.1)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow==2.17.1)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.17.1)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.17.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.17.1)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.17.1)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow==2.17.1)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.17.1)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.17.1)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.17.1)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.17.1)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.17.1)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow==2.17.1)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow==2.17.1)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.17.1)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.1) (0.45.1)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow==2.17.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.1)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.4/601.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.9 numpy-1.26.4 opt-einsum-3.4.0 optree-0.15.0 protobuf-4.25.6 rich-14.0.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.1 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Collecting matplotlib==3.9.2\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.9.2 pillow-11.2.1 pyparsing-3.2.3\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 12:08:51.142516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 12:08:51.163081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 12:08:51.168660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 2.8372\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.2800 - loss: 2.8014\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2800 - loss: 2.7607\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.2400 - loss: 2.7057\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2400 - loss: 2.6271\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.2400 - loss: 2.5177\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.2400 - loss: 2.3903\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2400 - loss: 2.3380\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.2400 - loss: 2.3679\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.2800 - loss: 2.2956\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 2.2209\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 2.1923\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.1796\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2000 - loss: 2.1554\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2800 - loss: 2.1112\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 2.0491\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3200 - loss: 1.9789\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.3200 - loss: 1.9192\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.3200 - loss: 1.8835\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3200 - loss: 1.8553\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.8089\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3200 - loss: 1.7498\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 1.6948\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.3200 - loss: 1.6462\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 1.6027\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.3200 - loss: 1.5697\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 1.5541\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.3200 - loss: 1.5361\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 1.5140\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.3200 - loss: 1.5007\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 1.4808\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3200 - loss: 1.4684\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.3200 - loss: 1.4600\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 1.4530\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.3600 - loss: 1.4423\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3200 - loss: 1.4289\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 1.4153\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.4159\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 1.3986\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 1.3819\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3200 - loss: 1.3746\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 1.3395\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3600 - loss: 1.3316\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4000 - loss: 1.3037\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4000 - loss: 1.2603\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4400 - loss: 1.2313\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4400 - loss: 1.1989\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.4800 - loss: 1.1595\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5200 - loss: 1.1170\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5600 - loss: 1.0731\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7200 - loss: 1.0311\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6000 - loss: 0.9908\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5600 - loss: 0.9639\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7200 - loss: 0.9555\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.4800 - loss: 0.9799\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5600 - loss: 0.9769\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6400 - loss: 0.9252\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5600 - loss: 0.9557\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5600 - loss: 0.9510\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4800 - loss: 0.9270\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6400 - loss: 0.8729\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6000 - loss: 0.8763\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6000 - loss: 0.8305\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.5600 - loss: 0.8692\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6800 - loss: 0.8065\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6400 - loss: 0.7767\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5600 - loss: 0.7569\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6400 - loss: 0.7367\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7200 - loss: 0.7339\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7600 - loss: 0.6878\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7200 - loss: 0.6644\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8000 - loss: 0.6601\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8400 - loss: 0.6383\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8800 - loss: 0.6144\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8400 - loss: 0.6041\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8400 - loss: 0.6061\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8400 - loss: 0.5909\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8400 - loss: 0.5759\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8400 - loss: 0.5590\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7600 - loss: 0.5496\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8800 - loss: 0.5378\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8400 - loss: 0.5294\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8400 - loss: 0.5180\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8800 - loss: 0.5016\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8400 - loss: 0.4843\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8800 - loss: 0.4688\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8400 - loss: 0.4686\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8800 - loss: 0.4220\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8800 - loss: 0.3892\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9600 - loss: 0.3820\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8800 - loss: 0.3680\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9600 - loss: 0.3338\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9600 - loss: 0.3200\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.3076\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.2819\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.2736\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.2579\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9600 - loss: 0.2434\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9600 - loss: 0.2266\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9600 - loss: 0.2147\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your answer here\n",
    "\n",
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_3… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_3… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0800 - loss: 2.8354\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 2.7897\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 2.7396\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 2.6754\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 2.5879\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.2800 - loss: 2.4707\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.2800 - loss: 2.3370\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.2400 - loss: 2.2726\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.2800 - loss: 2.3075\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 2.2488\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 2.1700\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.3200 - loss: 2.1115\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3200 - loss: 2.0645\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 2.0162\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3200 - loss: 1.9592\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 1.8963\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 1.8380\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3200 - loss: 1.7927\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 1.7550\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 1.7134\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.3200 - loss: 1.6695\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 1.6364\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2800 - loss: 1.6125\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.2800 - loss: 1.5632\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.3200 - loss: 1.5057\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 1.5037\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 1.5168\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.3200 - loss: 1.4990\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2800 - loss: 1.4855\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.3200 - loss: 1.4472\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.3200 - loss: 1.4492\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.3200 - loss: 1.4470\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 1.4438\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3600 - loss: 1.4299\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3600 - loss: 1.3999\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 1.3812\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.3200 - loss: 1.3515\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.3600 - loss: 1.3287\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.3600 - loss: 1.2792\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.4000 - loss: 1.2332\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.4800 - loss: 1.1916\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4000 - loss: 1.1489\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.4400 - loss: 1.1084\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5600 - loss: 1.0743\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5600 - loss: 1.0422\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5600 - loss: 1.0031\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6000 - loss: 0.9671\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5600 - loss: 0.9403\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5200 - loss: 0.9529\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.4800 - loss: 1.1781\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5200 - loss: 1.0123\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5200 - loss: 1.0360\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.5600 - loss: 0.8997\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5200 - loss: 1.0306\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5600 - loss: 0.9517\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6000 - loss: 0.9455\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5200 - loss: 0.9418\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6000 - loss: 0.9172\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6400 - loss: 0.9330\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6400 - loss: 0.8686\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6800 - loss: 0.8520\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7200 - loss: 0.8698\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7200 - loss: 0.8015\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6400 - loss: 0.8376\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7200 - loss: 0.8045\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7200 - loss: 0.7767\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7200 - loss: 0.7843\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7200 - loss: 0.7600\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7200 - loss: 0.7437\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7600 - loss: 0.7380\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7600 - loss: 0.7207\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7600 - loss: 0.7046\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7600 - loss: 0.6865\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7600 - loss: 0.6730\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7600 - loss: 0.6479\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7600 - loss: 0.6197\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8000 - loss: 0.6046\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8000 - loss: 0.5762\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8000 - loss: 0.5497\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8400 - loss: 0.5280\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8400 - loss: 0.5068\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8400 - loss: 0.4894\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8000 - loss: 0.4706\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8400 - loss: 0.4501\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8000 - loss: 0.4366\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8400 - loss: 0.4188\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8400 - loss: 0.4004\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8000 - loss: 0.3838\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8400 - loss: 0.3664\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8800 - loss: 0.3522\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8800 - loss: 0.3367\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8800 - loss: 0.3237\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.9200 - loss: 0.3107\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9200 - loss: 0.2976\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9600 - loss: 0.2856\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9200 - loss: 0.2742\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9600 - loss: 0.2645\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9600 - loss: 0.2535\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9600 - loss: 0.2432\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9600 - loss: 0.2320\n"
     ]
    }
   ],
   "source": [
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_5… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_5… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0400 - loss: 2.8348\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0400 - loss: 2.8342\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.0400 - loss: 2.8336\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.0400 - loss: 2.8330\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.0400 - loss: 2.8325\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.0400 - loss: 2.8319\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.0400 - loss: 2.8314\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0400 - loss: 2.8308\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.0400 - loss: 2.8303\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.0400 - loss: 2.8298\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.0800 - loss: 2.8292\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1200 - loss: 2.8287\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1200 - loss: 2.8282\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1200 - loss: 2.8277\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1600 - loss: 2.8272\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1600 - loss: 2.8267\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1600 - loss: 2.8261\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1600 - loss: 2.8256\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1600 - loss: 2.8252\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1600 - loss: 2.8247\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1600 - loss: 2.8242\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1600 - loss: 2.8237\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1600 - loss: 2.8232\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1600 - loss: 2.8227\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1600 - loss: 2.8222\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1600 - loss: 2.8217\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1600 - loss: 2.8213\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2800 - loss: 2.8208\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2800 - loss: 2.8203\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.2800 - loss: 2.8199\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2800 - loss: 2.8194\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.2800 - loss: 2.8189\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.8185\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.8180\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.8175\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2800 - loss: 2.8171\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2800 - loss: 2.8166\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2800 - loss: 2.8162\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2800 - loss: 2.8157\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2800 - loss: 2.8153\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.8148\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2800 - loss: 2.8144\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2800 - loss: 2.8139\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2800 - loss: 2.8135\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.8130\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.2800 - loss: 2.8126\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.2800 - loss: 2.8121\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.2800 - loss: 2.8117\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2800 - loss: 2.8113\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2800 - loss: 2.8108\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2800 - loss: 2.8104\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.8099\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2800 - loss: 2.8095\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2800 - loss: 2.8091\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2800 - loss: 2.8086\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2800 - loss: 2.8082\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.8078\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2800 - loss: 2.8074\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.2800 - loss: 2.8069\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2800 - loss: 2.8065\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.2800 - loss: 2.8061\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2800 - loss: 2.8057\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2800 - loss: 2.8052\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2800 - loss: 2.8048\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.8044\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.2800 - loss: 2.8040\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2800 - loss: 2.8036\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.8031\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2800 - loss: 2.8027\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.8023\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2800 - loss: 2.8019\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2800 - loss: 2.8015\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.2800 - loss: 2.8011\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2800 - loss: 2.8007\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2800 - loss: 2.8003\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2800 - loss: 2.7998\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2800 - loss: 2.7994\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2800 - loss: 2.7990\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2800 - loss: 2.7986\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.7982\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2800 - loss: 2.7978\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2800 - loss: 2.7974\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2800 - loss: 2.7970\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2800 - loss: 2.7966\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2800 - loss: 2.7962\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.2800 - loss: 2.7958\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2800 - loss: 2.7954\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2800 - loss: 2.7950\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2800 - loss: 2.7946\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2800 - loss: 2.7942\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2800 - loss: 2.7938\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2400 - loss: 2.7934\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2400 - loss: 2.7930\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2400 - loss: 2.7926\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2400 - loss: 2.7922\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2400 - loss: 2.7918\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2400 - loss: 2.7914\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2400 - loss: 2.7910\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2400 - loss: 2.7906\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2400 - loss: 2.7903\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Write your answer here\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "89fa9a3db18ab099ea8b241e966f29a2f658cfbd6a742128f10daea40c67df82"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
